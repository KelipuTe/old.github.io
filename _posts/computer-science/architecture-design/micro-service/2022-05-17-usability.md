---
title: "微服务可用性"
create_date: 2022-05-17 08:00:00 +0800
date: 2022-05-17 08:00:00 +0800
tags: computer-science micro-service
comment: false
show_author_profile: true
show_subscribe: false
---

- 隔离
  - 服务
    - 动静
    - 读写
  - 轻重
    - 核心非核心
    - 快慢
    - 热点
  - 物理
    - 线程
    - 进程
    - 集群
    - 机房
- 超时控制
  - 进程内超时控制
    - 连接超时
    - 读超时
    - 写超时
  - 服务间超时传递
  - 耗时的双峰分布
- load shedding（过载保护）和限流
  - 令牌桶限流
  - 漏桶限流
  - QPS 限流
  - 根据租户限流
    - 识别异常用户
  - 自适应限流
    - 采集系统指标
    - 利特尔法则
    - 滑动均值（滑动窗口）
  - 分布式限流
  - 根据接口优先级限流
  - 熔断
    - circuit breakers（断路器）
    - 客户端限流
- 降级
- 重试
  - 重试次数
  - 重试周期
  - 只在失败处重试
- 负载均衡

### 隔离

#### 服务隔离

动静隔离：动态数据和静态数据分开。缓存（加速）变换频次小的数据（静态数据）。

- 数据库冷热表（避免数据库缓存频繁被刷）
- CDN 静态资源加速

读写隔离：读取数据和写入数据分开。

如：主从、CQRS

#### 轻重隔离

- 核心非核心隔离：核心服务特殊部署
- 快慢隔离：将非关键路径上的耗时业务分离。如：业务处理（快）和记录日志（慢）分离。
- 热点隔离：某个数据突然变成热点，可能会影响到缓存集群整体的稳定时，需要单独提升为本地缓存。

#### 物理隔离

- 线程：不同的任务使用不同的线程池
- 进程：不同的服务放到不同的进程中执行
  - 把服务放到不同的容器中（docker）
  - 在 Linux 中，使用 cgroup 隔离每个进程的资源
- 集群：在多集群的基础上，不同的用户访问不同的集群
- 机房：在异地多活的基础上，不同的用户访问不同的机房

### 超时控制

双峰分布：95% 的请求是在合理范围内的，5% 的请求可能永远不会完成。

超时控制需要去关注 95 线或者 99 线。剩下的 5% 或者 1% 的高耗时请求是导致服务崩溃的关键。

### 过载保护和限流

过载保护的目的：

- 系统临近过载时，主动限流（抛弃请求），以求自保。
- 在系统稳定的前提下，尽可能保持系统的吞吐量。

拒绝请求也需要成本。

#### 自适应限流

在系统临近负载时（CPU 达到 90%、内存 达到 90% 等），使用利特尔法则和滑动均值（滑动窗口）测量系统理论最大流量，然后进行限流。

$系统理论最大流量 = QPS \times 请求平均响应时间$

#### 分布式限流

简单的实现：每来一个请求，redis +1。

复杂一点的实现：每次心跳，从限流器批量申请指标，然后本地用令牌桶。可以使用滑动窗口动态统计指标。

分配资源的方式：Max-Min Fairness（最大最小公平分享）

- 资源按照需求递增的顺序进行分配。
- 不存在用户得到的资源超过自己的需求。
- 未得到满足的用户等价的分享资源。

底层组件（数据库等）一定要做分布式限流。

#### 根据接口优先级限流

根据接口优先级限流可以和自适应限流和分布式限流配合使用。

- 达到某个负载的时候先丢弃低优先级的请求（自适应限流）。
- 高优先级的接口可以获得更多的指标（分布式限流）。

#### 熔断

熔断是对下游的保护。如果发现下游服务大量报错，就不请求下游直接返回错误。

### 降级

降级本质为提供有损服务。

### 重试

- 重试次数：限制重试次数
- 重试周期：随机化、指数型递增
- 只在失败处重试：底层重试过了，上层就不要重试了，避免级联重试。

### 负载均衡

p2c 算法：随机选取的两个节点进行打分，选择更优的节点。

- 对新启动的节点使用常量惩罚值（penalty），以及使用探针方式最小化放量，进行预热。
- 打分比较低的节点，避免进入“永久黑名单”而无法恢复，使用统计衰减的方式，让节点指标逐渐恢复到初始状态(即默认值)。
- 当前发出去的请求超过了 predict lagtency，就会加惩罚。